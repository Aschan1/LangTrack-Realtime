{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a275814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-5.2.0-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.12.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets[audio]\n",
      "  Using cached datasets-4.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting huggingface-hub<2.0,>=1.3.0 (from transformers)\n",
      "  Using cached huggingface_hub-1.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from transformers) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from transformers) (25.0)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2026.2.19-cp313-cp313-win_amd64.whl.metadata (41 kB)\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\n",
      "  Using cached tokenizers-0.22.2-cp39-abi3-win_amd64.whl.metadata (7.4 kB)\n",
      "Collecting typer-slim (from transformers)\n",
      "  Using cached typer_slim-0.24.0-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Using cached tqdm-4.67.3-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: filelock>=3.10.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.12.0)\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached hf_xet-1.3.1-cp37-abi3-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typer (from huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached typer-0.24.1-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached certifi-2026.2.25-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting pyarrow>=21.0.0 (from datasets[audio])\n",
      "  Using cached pyarrow-23.0.1-cp313-cp313-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets[audio])\n",
      "  Using cached dill-0.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets[audio])\n",
      "  Using cached pandas-3.0.1-cp313-cp313-win_amd64.whl.metadata (19 kB)\n",
      "Collecting requests>=2.32.2 (from datasets[audio])\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting xxhash (from datasets[audio])\n",
      "  Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.19 (from datasets[audio])\n",
      "  Using cached multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\n",
      "Collecting torchcodec>=0.6.0 (from datasets[audio])\n",
      "  Using cached torchcodec-0.10.0-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: torch>=2.8.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from datasets[audio]) (2.9.1+cu130)\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2026.2.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached aiohttp-3.13.3-cp313-cp313-win_amd64.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: psutil in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from accelerate) (7.2.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached frozenlist-1.8.0-cp313-cp313-win_amd64.whl.metadata (21 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached multidict-6.7.1-cp313-cp313-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached propcache-0.4.1-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2026.2.0,>=2023.1.0->datasets[audio])\n",
      "  Using cached yarl-1.22.0-cp313-cp313-win_amd64.whl.metadata (77 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.32.2->datasets[audio])\n",
      "  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.32.2->datasets[audio])\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=2.8.0->datasets[audio]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=2.8.0->datasets[audio]) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=2.8.0->datasets[audio]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=2.8.0->datasets[audio]) (80.10.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from sympy>=1.13.3->torch>=2.8.0->datasets[audio]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from jinja2->torch>=2.8.0->datasets[audio]) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Collecting tzdata (from pandas->datasets[audio])\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.17.0)\n",
      "Collecting click>=8.2.1 (from typer->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=12.3.0 (from typer->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached rich-14.3.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting annotated-doc>=0.0.2 (from typer->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=12.3.0->typer->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from rich>=12.3.0->typer->huggingface-hub<2.0,>=1.3.0->transformers) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=12.3.0->typer->huggingface-hub<2.0,>=1.3.0->transformers)\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Using cached transformers-5.2.0-py3-none-any.whl (10.4 MB)\n",
      "Using cached huggingface_hub-1.5.0-py3-none-any.whl (596 kB)\n",
      "Using cached hf_xet-1.3.1-cp37-abi3-win_amd64.whl (3.6 MB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Using cached tokenizers-0.22.2-cp39-abi3-win_amd64.whl (2.7 MB)\n",
      "Using cached datasets-4.6.0-py3-none-any.whl (520 kB)\n",
      "Using cached dill-0.4.0-py3-none-any.whl (119 kB)\n",
      "Using cached multiprocess-0.70.18-py313-none-any.whl (151 kB)\n",
      "Using cached accelerate-1.12.0-py3-none-any.whl (380 kB)\n",
      "Using cached aiohttp-3.13.3-cp313-cp313-win_amd64.whl (453 kB)\n",
      "Using cached multidict-6.7.1-cp313-cp313-win_amd64.whl (45 kB)\n",
      "Using cached yarl-1.22.0-cp313-cp313-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached frozenlist-1.8.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached propcache-0.4.1-cp313-cp313-win_amd64.whl (40 kB)\n",
      "Using cached pyarrow-23.0.1-cp313-cp313-win_amd64.whl (27.5 MB)\n",
      "Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)\n",
      "Using cached regex-2026.2.19-cp313-cp313-win_amd64.whl (277 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Using cached certifi-2026.2.25-py3-none-any.whl (153 kB)\n",
      "Using cached safetensors-0.7.0-cp38-abi3-win_amd64.whl (341 kB)\n",
      "Using cached torchcodec-0.10.0-cp313-cp313-win_amd64.whl (2.2 MB)\n",
      "Using cached tqdm-4.67.3-py3-none-any.whl (78 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached pandas-3.0.1-cp313-cp313-win_amd64.whl (9.7 MB)\n",
      "Using cached typer-0.24.1-py3-none-any.whl (56 kB)\n",
      "Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached rich-14.3.3-py3-none-any.whl (310 kB)\n",
      "Using cached markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached typer_slim-0.24.0-py3-none-any.whl (3.4 kB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Using cached xxhash-3.6.0-cp313-cp313-win_amd64.whl (31 kB)\n",
      "Installing collected packages: xxhash, urllib3, tzdata, tqdm, torchcodec, shellingham, safetensors, regex, pyyaml, pyarrow, propcache, multidict, mdurl, idna, hf-xet, h11, frozenlist, dill, click, charset_normalizer, certifi, attrs, annotated-doc, aiohappyeyeballs, yarl, requests, pandas, multiprocess, markdown-it-py, httpcore, anyio, aiosignal, rich, httpx, aiohttp, typer, typer-slim, huggingface-hub, tokenizers, datasets, accelerate, transformers\n",
      "\n",
      "    ---------------------------------------  1/42 [urllib3]\n",
      "    ---------------------------------------  1/42 [urllib3]\n",
      "   - --------------------------------------  2/42 [tzdata]\n",
      "   - --------------------------------------  2/42 [tzdata]\n",
      "   - --------------------------------------  2/42 [tzdata]\n",
      "   - --------------------------------------  2/42 [tzdata]\n",
      "   - --------------------------------------  2/42 [tzdata]\n",
      "   -- -------------------------------------  3/42 [tqdm]\n",
      "   -- -------------------------------------  3/42 [tqdm]\n",
      "   --- ------------------------------------  4/42 [torchcodec]\n",
      "   --- ------------------------------------  4/42 [torchcodec]\n",
      "   ----- ----------------------------------  6/42 [safetensors]\n",
      "   ------ ---------------------------------  7/42 [regex]\n",
      "   ------- --------------------------------  8/42 [pyyaml]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   -------- -------------------------------  9/42 [pyarrow]\n",
      "   --------- ------------------------------ 10/42 [propcache]\n",
      "   ------------ --------------------------- 13/42 [idna]\n",
      "   ------------ --------------------------- 13/42 [idna]\n",
      "   -------------- ------------------------- 15/42 [h11]\n",
      "   ---------------- ----------------------- 17/42 [dill]\n",
      "   ---------------- ----------------------- 17/42 [dill]\n",
      "   ---------------- ----------------------- 17/42 [dill]\n",
      "   ----------------- ---------------------- 18/42 [click]\n",
      "   ----------------- ---------------------- 18/42 [click]\n",
      "   ------------------ --------------------- 19/42 [charset_normalizer]\n",
      "   -------------------- ------------------- 21/42 [attrs]\n",
      "   -------------------- ------------------- 21/42 [attrs]\n",
      "   ---------------------- ----------------- 24/42 [yarl]\n",
      "   ----------------------- ---------------- 25/42 [requests]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------ --------------- 26/42 [pandas]\n",
      "   ------------------------- -------------- 27/42 [multiprocess]\n",
      "   ------------------------- -------------- 27/42 [multiprocess]\n",
      "   -------------------------- ------------- 28/42 [markdown-it-py]\n",
      "   -------------------------- ------------- 28/42 [markdown-it-py]\n",
      "   -------------------------- ------------- 28/42 [markdown-it-py]\n",
      "   -------------------------- ------------- 28/42 [markdown-it-py]\n",
      "   --------------------------- ------------ 29/42 [httpcore]\n",
      "   ---------------------------- ----------- 30/42 [anyio]\n",
      "   ---------------------------- ----------- 30/42 [anyio]\n",
      "   ---------------------------- ----------- 30/42 [anyio]\n",
      "   ------------------------------ --------- 32/42 [rich]\n",
      "   ------------------------------ --------- 32/42 [rich]\n",
      "   ------------------------------ --------- 32/42 [rich]\n",
      "   ------------------------------ --------- 32/42 [rich]\n",
      "   ------------------------------ --------- 32/42 [rich]\n",
      "   ------------------------------ --------- 32/42 [rich]\n",
      "   ------------------------------ --------- 32/42 [rich]\n",
      "   ------------------------------- -------- 33/42 [httpx]\n",
      "   -------------------------------- ------- 34/42 [aiohttp]\n",
      "   -------------------------------- ------- 34/42 [aiohttp]\n",
      "   -------------------------------- ------- 34/42 [aiohttp]\n",
      "   -------------------------------- ------- 34/42 [aiohttp]\n",
      "   --------------------------------- ------ 35/42 [typer]\n",
      "   --------------------------------- ------ 35/42 [typer]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ----------------------------------- ---- 37/42 [huggingface-hub]\n",
      "   ------------------------------------ --- 38/42 [tokenizers]\n",
      "   ------------------------------------- -- 39/42 [datasets]\n",
      "   ------------------------------------- -- 39/42 [datasets]\n",
      "   ------------------------------------- -- 39/42 [datasets]\n",
      "   ------------------------------------- -- 39/42 [datasets]\n",
      "   ------------------------------------- -- 39/42 [datasets]\n",
      "   ------------------------------------- -- 39/42 [datasets]\n",
      "   ------------------------------------- -- 39/42 [datasets]\n",
      "   ------------------------------------- -- 39/42 [datasets]\n",
      "   -------------------------------------- - 40/42 [accelerate]\n",
      "   -------------------------------------- - 40/42 [accelerate]\n",
      "   -------------------------------------- - 40/42 [accelerate]\n",
      "   -------------------------------------- - 40/42 [accelerate]\n",
      "   -------------------------------------- - 40/42 [accelerate]\n",
      "   -------------------------------------- - 40/42 [accelerate]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------  41/42 [transformers]\n",
      "   ---------------------------------------- 42/42 [transformers]\n",
      "\n",
      "Successfully installed accelerate-1.12.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.3 aiosignal-1.4.0 annotated-doc-0.0.4 anyio-4.12.1 attrs-25.4.0 certifi-2026.2.25 charset_normalizer-3.4.4 click-8.3.1 datasets-4.6.0 dill-0.4.0 frozenlist-1.8.0 h11-0.16.0 hf-xet-1.3.1 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-1.5.0 idna-3.11 markdown-it-py-4.0.0 mdurl-0.1.2 multidict-6.7.1 multiprocess-0.70.18 pandas-3.0.1 propcache-0.4.1 pyarrow-23.0.1 pyyaml-6.0.3 regex-2026.2.19 requests-2.32.5 rich-14.3.3 safetensors-0.7.0 shellingham-1.5.4 tokenizers-0.22.2 torchcodec-0.10.0 tqdm-4.67.3 transformers-5.2.0 typer-0.24.1 typer-slim-0.24.0 tzdata-2025.3 urllib3-2.6.3 xxhash-3.6.0 yarl-1.22.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade transformers datasets[audio] accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "938f7633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddevice\n",
      "  Using cached sounddevice-0.5.5-py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting cffi (from sounddevice)\n",
      "  Using cached cffi-2.0.0-cp313-cp313-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pycparser (from cffi->sounddevice)\n",
      "  Using cached pycparser-3.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Using cached sounddevice-0.5.5-py3-none-win_amd64.whl (365 kB)\n",
      "Using cached cffi-2.0.0-cp313-cp313-win_amd64.whl (183 kB)\n",
      "Using cached pycparser-3.0-py3-none-any.whl (48 kB)\n",
      "Installing collected packages: pycparser, cffi, sounddevice\n",
      "\n",
      "   ---------------------------------------- 0/3 [pycparser]\n",
      "   ------------- -------------------------- 1/3 [cffi]\n",
      "   ------------- -------------------------- 1/3 [cffi]\n",
      "   -------------------------- ------------- 2/3 [sounddevice]\n",
      "   ---------------------------------------- 3/3 [sounddevice]\n",
      "\n",
      "Successfully installed cffi-2.0.0 pycparser-3.0 sounddevice-0.5.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting soundfile\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from soundfile) (2.0.0)\n",
      "Requirement already satisfied: numpy in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from soundfile) (2.3.5)\n",
      "Requirement already satisfied: pycparser in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from cffi>=1.0->soundfile) (3.0)\n",
      "Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "Installing collected packages: soundfile\n",
      "Successfully installed soundfile-0.13.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting silero-vad\n",
      "  Using cached silero_vad-6.2.1-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: packaging in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from silero-vad) (25.0)\n",
      "Requirement already satisfied: torch>=1.12.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from silero-vad) (2.9.1+cu130)\n",
      "Requirement already satisfied: torchaudio>=0.12.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from silero-vad) (2.9.1+cu130)\n",
      "Requirement already satisfied: filelock in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=1.12.0->silero-vad) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=1.12.0->silero-vad) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=1.12.0->silero-vad) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=1.12.0->silero-vad) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=1.12.0->silero-vad) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=1.12.0->silero-vad) (2025.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from torch>=1.12.0->silero-vad) (80.10.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from sympy>=1.13.3->torch>=1.12.0->silero-vad) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from jinja2->torch>=1.12.0->silero-vad) (3.0.2)\n",
      "Using cached silero_vad-6.2.1-py3-none-any.whl (9.1 MB)\n",
      "Installing collected packages: silero-vad\n",
      "Successfully installed silero-vad-6.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install sounddevice\n",
    "%pip install soundfile\n",
    "#Install the silero VAD model for voice activity detection\n",
    "%pip install silero-vad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "994282f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scipy\n",
      "  Using cached scipy-1.17.1-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: numpy<2.7,>=1.26.4 in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (from scipy) (2.3.5)\n",
      "Using cached scipy-1.17.1-cp313-cp313-win_amd64.whl (36.5 MB)\n",
      "Installing collected packages: scipy\n",
      "Successfully installed scipy-1.17.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2f3b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchcodec in c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages (0.10.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torchcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2113a036",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sounddevice as sd\n",
    "import queue\n",
    "import threading\n",
    "from scipy.signal import resample_poly\n",
    "from math import gcd\n",
    "import soundfile as so\n",
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from datasets import load_dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7610b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as so\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "dll_path = Path(r\"C:\\Users\\pavlo\\miniconda3\\Library\\bin\")\n",
    "\n",
    "if dll_path.exists():\n",
    "    os.add_dll_directory(str(dll_path))\n",
    "else:\n",
    "    print(f\"Warning: {dll_path} not found. Check your Miniconda path.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db05ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pavlo\\miniconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\pavlo\\.cache\\huggingface\\hub\\models--openai--whisper-tiny. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Loading weights: 100%|██████████| 167/167 [00:00<00:00, 578.70it/s, Materializing param=model.encoder.layers.3.self_attn_layer_norm.weight]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similarly drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Latins' work is really Greek after all, and can discover in it but little of Rocky Ithaca. Lennils, pictures, are a sort of upguards and atom paintings, and Mason's exquisite itals are as national as a jingo poem. Mr. Birkut Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampoo and a turkish bath. Next man.\n"
     ]
    }
   ],
   "source": [
    "# Trying out Whisper tiny from: https://huggingface.co/openai/whisper-large-v3\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-tiny\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "device_for_pipeline = 0 if torch.cuda.is_available() else -1\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device_for_pipeline,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\",streaming=True)\n",
    "sample = next(iter(dataset))\n",
    "audio_sample=sample[\"audio\"]\n",
    "if isinstance(audio_sample,dict) and \"array\" in audio_sample:\n",
    "    audio_input = audio_sample[\"array\"]\n",
    "elif isinstance(audio_sample,dict) and \"path\" in audio_sample:\n",
    "    audio_input = so.read(audio_sample[\"path\"])\n",
    "else:\n",
    "    audio_input = audio_sample\n",
    "result = pipe(audio_input,return_timestamps=True)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93cca2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\python.exe\n",
      "torch: 2.9.1+cu130\n",
      "CUDA_VISIBLE_DEVICES: None\n"
     ]
    }
   ],
   "source": [
    "import sys, torch, os\n",
    "print(\"python:\", sys.executable)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "895ef24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.0\n"
     ]
    }
   ],
   "source": [
    "fc = torch.version.cuda\n",
    "print(fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f173837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading weights: 100%|██████████| 167/167 [00:00<00:00, 227.13it/s, Materializing param=model.encoder.layers.3.self_attn_layer_norm.weight]  \n",
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Using cache found in C:\\Users\\pavlo/.cache\\torch\\hub\\snakers4_silero-vad_master\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting real-time transcription. Press Ctrl+C to stop.\n",
      "Speech segment lasting 0.8s complete. Transcribing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-16 (process_audio):\n",
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\threading.py\"\u001b[0m, line \u001b[35m1044\u001b[0m, in \u001b[35m_bootstrap_inner\u001b[0m\n",
      "    \u001b[31mself.run\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "    \u001b[31m~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\threading.py\"\u001b[0m, line \u001b[35m995\u001b[0m, in \u001b[35mrun\u001b[0m\n",
      "    \u001b[31mself._target\u001b[0m\u001b[1;31m(*self._args, **self._kwargs)\u001b[0m\n",
      "    \u001b[31m~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"C:\\Users\\pavlo\\AppData\\Local\\Temp\\ipykernel_47460\\1429259374.py\"\u001b[0m, line \u001b[35m97\u001b[0m, in \u001b[35mprocess_audio\u001b[0m\n",
      "    res = transcribe(sbuf)#The current speech segment in the speech buffer is transcribed using the Whisper model\n",
      "  File \u001b[35m\"C:\\Users\\pavlo\\AppData\\Local\\Temp\\ipykernel_47460\\1429259374.py\"\u001b[0m, line \u001b[35m70\u001b[0m, in \u001b[35mtranscribe\u001b[0m\n",
      "    result = pipe(audio_a)#Transcribe the speech segment using the Whisper model and get the transcription result with timestamps\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py\"\u001b[0m, line \u001b[35m266\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    return \u001b[31msuper().__call__\u001b[0m\u001b[1;31m(inputs, **kwargs)\u001b[0m\n",
      "           \u001b[31m~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\transformers\\pipelines\\base.py\"\u001b[0m, line \u001b[35m1266\u001b[0m, in \u001b[35m__call__\u001b[0m\n",
      "    return next(\n",
      "        iter(\n",
      "    ...<3 lines>...\n",
      "        )\n",
      "    )\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py\"\u001b[0m, line \u001b[35m126\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    item = next(self.iterator)\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py\"\u001b[0m, line \u001b[35m271\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    processed = self.infer(\u001b[31mnext\u001b[0m\u001b[1;31m(self.iterator)\u001b[0m, **self.params)\n",
      "                           \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\"\u001b[0m, line \u001b[35m732\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    data = self._next_data()\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py\"\u001b[0m, line \u001b[35m788\u001b[0m, in \u001b[35m_next_data\u001b[0m\n",
      "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\"\u001b[0m, line \u001b[35m33\u001b[0m, in \u001b[35mfetch\u001b[0m\n",
      "    data.append(\u001b[31mnext\u001b[0m\u001b[1;31m(self.dataset_iter)\u001b[0m)\n",
      "                \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\transformers\\pipelines\\pt_utils.py\"\u001b[0m, line \u001b[35m188\u001b[0m, in \u001b[35m__next__\u001b[0m\n",
      "    processed = next(self.subiterator)\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\transformers\\pipelines\\automatic_speech_recognition.py\"\u001b[0m, line \u001b[35m386\u001b[0m, in \u001b[35mpreprocess\u001b[0m\n",
      "    import torchcodec\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\__init__.py\"\u001b[0m, line \u001b[35m12\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    \u001b[1;31mfrom . import decoders, encoders, samplers, transforms\u001b[0m  # noqa\n",
      "    \u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\decoders\\__init__.py\"\u001b[0m, line \u001b[35m7\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from .._core import AudioStreamMetadata, VideoStreamMetadata\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\__init__.py\"\u001b[0m, line \u001b[35m8\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from ._metadata import (\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\_metadata.py\"\u001b[0m, line \u001b[35m16\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from torchcodec._core.ops import (\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\ops.py\"\u001b[0m, line \u001b[35m109\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    ffmpeg_major_version, core_library_path = \u001b[31mload_torchcodec_shared_libraries\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "                                              \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "  File \u001b[35m\"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\ops.py\"\u001b[0m, line \u001b[35m76\u001b[0m, in \u001b[35mload_torchcodec_shared_libraries\u001b[0m\n",
      "    raise RuntimeError(\n",
      "    ...<16 lines>...\n",
      "    )\n",
      "\u001b[1;35mRuntimeError\u001b[0m: \u001b[35mCould not load libtorchcodec. Likely causes:\n",
      "          1. FFmpeg is not properly installed in your environment. We support\n",
      "             versions 4, 5, 6, 7, and 8, and we attempt to load libtorchcodec\n",
      "             for each of those versions. Errors for versions not installed on\n",
      "             your system are expected; only the error for your installed FFmpeg\n",
      "             version is relevant. On Windows, ensure you've installed the\n",
      "             \"full-shared\" version which ships DLLs.\n",
      "          2. The PyTorch version (2.9.1+cu130) is not compatible with\n",
      "             this version of TorchCodec. Refer to the version compatibility\n",
      "             table:\n",
      "             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n",
      "          3. Another runtime dependency; see exceptions below.\n",
      "\n",
      "        The following exceptions were raised as we tried to load libtorchcodec:\n",
      "        \n",
      "[start of libtorchcodec loading traceback]\n",
      "FFmpeg version 8:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1488, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 361, in __init__\n",
      "    self._handle = self._load_library(name, mode, handle, winmode)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 379, in _load_library\n",
      "    return _LoadLibrary(self._name, winmode)\n",
      "FileNotFoundError: Could not find module 'C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core8.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1490, in load_library\n",
      "    raise OSError(f\"Could not load this library: {path}\") from e\n",
      "OSError: Could not load this library: C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core8.dll\n",
      "\n",
      "FFmpeg version 7:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1488, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 361, in __init__\n",
      "    self._handle = self._load_library(name, mode, handle, winmode)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 379, in _load_library\n",
      "    return _LoadLibrary(self._name, winmode)\n",
      "OSError: [WinError 127] The specified procedure could not be found\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1490, in load_library\n",
      "    raise OSError(f\"Could not load this library: {path}\") from e\n",
      "OSError: Could not load this library: C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core7.dll\n",
      "\n",
      "FFmpeg version 6:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1488, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 361, in __init__\n",
      "    self._handle = self._load_library(name, mode, handle, winmode)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 379, in _load_library\n",
      "    return _LoadLibrary(self._name, winmode)\n",
      "FileNotFoundError: Could not find module 'C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core6.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1490, in load_library\n",
      "    raise OSError(f\"Could not load this library: {path}\") from e\n",
      "OSError: Could not load this library: C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core6.dll\n",
      "\n",
      "FFmpeg version 5:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1488, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 361, in __init__\n",
      "    self._handle = self._load_library(name, mode, handle, winmode)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 379, in _load_library\n",
      "    return _LoadLibrary(self._name, winmode)\n",
      "FileNotFoundError: Could not find module 'C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core5.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1490, in load_library\n",
      "    raise OSError(f\"Could not load this library: {path}\") from e\n",
      "OSError: Could not load this library: C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core5.dll\n",
      "\n",
      "FFmpeg version 4:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1488, in load_library\n",
      "    ctypes.CDLL(path)\n",
      "    ~~~~~~~~~~~^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 361, in __init__\n",
      "    self._handle = self._load_library(name, mode, handle, winmode)\n",
      "                   ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\ctypes\\__init__.py\", line 379, in _load_library\n",
      "    return _LoadLibrary(self._name, winmode)\n",
      "FileNotFoundError: Could not find module 'C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core4.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\_core\\ops.py\", line 57, in load_torchcodec_shared_libraries\n",
      "    torch.ops.load_library(core_library_path)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torch\\_ops.py\", line 1490, in load_library\n",
      "    raise OSError(f\"Could not load this library: {path}\") from e\n",
      "OSError: Could not load this library: C:\\Users\\pavlo\\miniconda3\\envs\\whisper4\\Lib\\site-packages\\torchcodec\\libtorchcodec_core4.dll\n",
      "[end of libtorchcodec loading traceback].\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping real-time transcription...\n"
     ]
    }
   ],
   "source": [
    "mf_s=44100 #Standard microphone sampling rate\n",
    "tf_s=16000 #Silero required sampling rate; https://github.com/snakers4/silero-vad/wiki/Performance-Metrics#silero-vad-performance-metrics\n",
    "chunk_size = 32.0 #ms (nominal chunk size for silero (512 chunks at 16kHz); https://github.com/snakers4/silero-vad/wiki/Performance-Metrics#silero-vad-performance-metrics)\n",
    "nsm=int(mf_s*chunk_size/1000)#Number of samples in each chunk with the microphone sampling rate (1323 samples at 44.1kHz)\n",
    "nst=int(tf_s*chunk_size/1000)#Number of samples in each chunk with the target sampling rate (480 samples at 16kHz)\n",
    "min_speech_duration = 0.25 # 250ms minimum speech to be valid\n",
    "VAD_threshold = 0.5 #Silero-VAD's output is a probability of voice presence in the current chunk. The probability value is thresholded to determine a speech classification (https://github.com/snakers4/silero-vad/wiki/Quality-Metrics#probability).\n",
    "st=2.0#Silence time threshold in seconds; if the VAD detects silence for this amount of time, it will consider the speech segment to be complete\n",
    "maxd=10.0#Maximum duration of a speech segment in seconds; if the VAD detects speech for this amount of time, it will consider the speech segment to be complete and buffer will be flushed\n",
    "\n",
    "#Load models\n",
    "model_id = \"openai/whisper-tiny\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)    \n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "#device_for_pipeline = 0 if torch.cuda.is_available() else -1\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "#Initialize VAD https://github.com/snakers4/silero-vad\n",
    "torch.set_num_threads(1)\n",
    "vad, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad', model='silero_vad')\n",
    "vad.eval()#Set the VAD to evaluation mode\n",
    "(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils#Extract the utility functions from the silero VAD utils https://medium.com/@aidenkoh/how-to-implement-high-speed-voice-recognition-in-chatbot-systems-with-whisperx-silero-vad-cdd45ea30904\n",
    "# Initialize VADIterator\n",
    "vad_iterator = VADIterator(vad, sampling_rate=tf_s, threshold=VAD_threshold)\n",
    "\n",
    "aq=queue.Queue()#Audio queue for communication between the audio callback and the main thread\n",
    "sbuf=[]#Speech buffer to store the current speech segment\n",
    "scount=0#Silence counter\n",
    "speaking=False#Flag to indicate if the user is currently speaking\n",
    "\n",
    "sb=int(st*(1000/chunk_size))#Number of consecutive silent chunks required to consider the speech segment complete\n",
    "spb=int(maxd*(1000/chunk_size))#Number of consecutive speech chunks required to consider the speech segment complete\n",
    "min_spb = int(min_speech_duration * (1000 / chunk_size)) # Minimum chunks required for chunk to be considered valid speech segment\n",
    "\n",
    "#Function to add audio samples to queue\n",
    "def inq(insamples, frames, time_info, status):\n",
    "    if status:\n",
    "        print(status)\n",
    "    aq.put(insamples)#Add the incoming audio samples to the queue (queue method: https://www.geeksforgeeks.org/python/queue-in-python/)\n",
    "#Function to resample audio samples from the microphone sampling rate to the target sampling rate required by the VAD model\n",
    "def resample(inaudio):\n",
    "    seq=inaudio.flatten().astype(np.float32) #Get the audio samples from the queue\n",
    "    #Resampling is input f*(tf_s/mf_s), i.e. mf_s*(tf_s/mf_s)=tf_s=16KHz. Better than using scipy.signal.resample, which adds samples and might introduce artifacts or aliasing effects. This allows for more control over frequencies. \n",
    "    resampled = resample_poly(seq, tf_s, mf_s)#Resample the audio samples to the target sampling rate using polyphase filtering (up then down conversion with appropriate anti-aliasing filtering after down conversion) (scipy method: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample_poly.html)\n",
    "    return resampled.astype('float32')#Return the resampled audio samples as float32 (required by silero VAD; https://medium.com/@aidenkoh/how-to-implement-high-speed-voice-recognition-in-chatbot-systems-with-whisperx-silero-vad-cdd45ea30904)\n",
    "\n",
    "#Silero-VAD inference function\n",
    "def VAD_prob(sample_16k):\n",
    "    with torch.no_grad():#Disable gradient calculation for inference\n",
    "        audio_tensor = torch.from_numpy(sample_16k).float().unsqueeze(0)#Convert the resampled audio samples to a PyTorch tensor and add a batch dimension\n",
    "        #prob = vad(audio_tensor, tf_s).item()#Get the VAD probability of voice presence in the current chunk (sampling rate not passed as keyword argument detected after error:Error in process_audio: RuntimeError: forward() is missing value for argument 'sr')\n",
    "        vad_iterator(audio_tensor, return_seconds=True)\n",
    "    return 1.0 if vad_iterator.triggered else 0.0#Detect if threshold is triggered and return 1.0 for speech and 0.0 for silence based on the VAD iterator's triggered state \n",
    "\n",
    "#Whisper inference function\n",
    "def transcribe(speech_Segment):\n",
    "    audio_a=np.concatenate(speech_Segment, axis=0)#Concatenate the audio chunks in the speech buffer to form a complete speech segment\n",
    "    audio_a=audio_a/(np.max(np.abs(audio_a))+1e-6)#Normalize the audio samples to the range [-1, 1] to prevent clipping and ensure consistent volume levels \n",
    "    result = pipe(audio_a)#Transcribe the speech segment using the Whisper model and get the transcription result with timestamps\n",
    "    #print(result[\"text\"])#Print the transcribed text from the speech segment\n",
    "    return result[\"text\"]#Return the transcribed text from the speech segment\n",
    "    \n",
    "#Process audio chunks from the queue and perform VAD and transcription\n",
    "def process_audio():\n",
    "    global scount, speaking, sbuf\n",
    "    while True:\n",
    "        audio = aq.get()#Get the next audio chunk from the queue\n",
    "        if audio is None:#If the audio chunk is None, it means the audio stream has ended, so the loop is exited\n",
    "            break\n",
    "        resampled_16=resample(audio)#Resample the audio chunk to the target sampling rate (16KHz) required by the VAD model\n",
    "        if len(resampled_16) < nst:#If the resampled audio chunk is shorter than the expected number of samples for the VAD model, it is padded with zeros to ensure consistent input size\n",
    "            resampled_16 = np.pad(resampled_16, (0, nst - len(resampled_16)))\n",
    "        if len(resampled_16) > nst:#If the resampled audio chunk is longer than the expected number of samples for the VAD model, it is truncated to ensure teh target number of samples for the VAD\n",
    "            resampled_16 = resampled_16[:nst]\n",
    "        prob = VAD_prob(resampled_16)#Get the VAD probability of voice presence in the current chunk\n",
    "        if VAD_prob(resampled_16):#If the VAD probability exceeds the threshold, it is classified as speech\n",
    "            sbuf.append(resampled_16)#The resampled audio chunk is added to the speech buffer\n",
    "            scount=0#The silence counter is set to zero since speech is detected\n",
    "            speaking=True#Set the speaking flag to True since speech is detected\n",
    "        else:#If the VAD probability does not exceed the threshold, it is classified as silence\n",
    "            if speaking: #If the speaker was previously speaking, the silence counter is incremented\n",
    "                scount += 1\n",
    "                if scount >= sb or len(sbuf) >= spb:#If the silence counter exceeds the silence threshold or the speech segments exceed the maximum number of speech segments\n",
    "                    if len(sbuf) >= min_spb:#If the number of speech segments in the buffer exceeds the minimum required for a valid speech segment, it is transcribed\n",
    "                        print(f\"Speech segment lasting {len(sbuf)*(maxd/1000):.1f}s complete. Transcribing...\")\n",
    "                        res = transcribe(sbuf)#The current speech segment in the speech buffer is transcribed using the Whisper model\n",
    "                        sbuf=[]#The speech buffer is cleared to prepare for the next speech segment\n",
    "                        scount=0#The silence counter is reset to zero\n",
    "                        speaking=False#Set the speaking flag to False since the speech segment is complete\n",
    "                        print(f\"[Transcript]: {res}\")#Print the transcribed text from the speech segment\n",
    "                    else:#If the number of speech segments in the buffer does not exceed the minimum required for a valid speech segment, it is discarded\n",
    "                        sbuf=[]#The speech buffer is cleared to discard the current speech segment\n",
    "                        scount=0#The silence counter is reset to zero\n",
    "                        speaking=False#Set the speaking flag to False since the speech segment is discarded\n",
    "                        print(f\"Discarded speech segment lasting {len(sbuf)*(maxd/1000):.1f}s due to insufficient duration.\")#Print a message indicating that the speech segment was discarded due to insufficient duration\n",
    "#Real-time transcription in main\n",
    "def main():\n",
    "    print(\"Starting real-time transcription. Press Ctrl+C to stop.\")\n",
    "    #Threads: https://www.geeksforgeeks.org/python/multithreading-python-set-1/\n",
    "    audio_thread = threading.Thread(target=process_audio)#Create a thread to process the audio chunks from the queue and perform VAD and transcription\n",
    "    audio_thread.start()#Start the audio processing thread\n",
    "    #Exception of keyboard interrupt to stop the audio-streaming and transcription \n",
    "    try:\n",
    "        with sd.InputStream(samplerate=mf_s, channels=1, callback=inq, blocksize=nsm, dtype='float32'):#Start an audio input stream with the specified sampling rate, number of \n",
    "            #channels, callback function, block size, and data type\n",
    "            #https://python-sounddevice.readthedocs.io/en/0.4.1/usage.html\n",
    "            #Explanation of why the main thread needs to be kept alive: The audio stream runs in a separate thread and continuously captures audio data from the microphone.\n",
    "            #If the main thread were to be terminated, the audio stream would also be stopped, and the real-time transcription would not work. By keeping the main thread alive, \n",
    "            # we ensure that the audio stream continues to run and \n",
    "            # captures audio data for processing by the VAD and Whisper models.\n",
    "            while True:\n",
    "                sd.sleep(1000)#Keep the main thread alive while the audio stream is active\n",
    "    except KeyboardInterrupt: #https://www.geeksforgeeks.org/python/how-to-catch-a-keyboardinterrupt-in-python/\n",
    "        print(\"Stopping real-time transcription...\")\n",
    "        aq.put(None)#Signal the audio processing thread to stop by putting None in the queue\n",
    "        audio_thread.join()#Wait for the audio processing thread to finish https://www.geeksforgeeks.org/python/multithreading-python-set-1/\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "whisper4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
